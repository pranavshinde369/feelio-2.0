# Feelio - Production-Ready AI Therapist

## ğŸ“¦ What You Have

A complete, production-ready multimodal AI therapist system with:

- âœ… **Voice I/O** - Speech recognition + text-to-speech
- âœ… **Solution-focused therapy** - Validates emotions then offers concrete actions
- âœ… **Session tracking** - Logs turns, generates end-of-session summaries
- âœ… **Safety protocol** - Detects self-harm keywords, crisis response
- âœ… **Adaptive pacing** - Slows down responses if user speaks fast
- âœ… **Playbook selector** - Offers specific coping strategies per emotion
- âœ… **Structured logging** - Production-grade error tracking
- âœ… **Config management** - `.env` based, no hardcoded secrets
- âœ… **Modular architecture** - Clean separation of concerns

---

## ğŸš€ Quick Start (3 steps)

### Step 1: Create `.env` file
```bash
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY
```

### Step 2: Install dependencies
```bash
pip install -r requirements.txt
```

### Step 3: Run
```bash
python main.py
```

That's it! The app will:
1. Listen for your voice
2. Transcribe it
3. Send to Gemini with therapy context
4. Speak the response back to you
5. Log everything in `feelio.log`

---

## ğŸ“ Project Structure

```
feelio/
â”œâ”€â”€ main.py                 # ğŸ¯ PRODUCTION ENTRY POINT
â”œâ”€â”€ config.py               # Configuration management + validation
â”œâ”€â”€ audio_module.py         # Speech recognition + TTS encapsulation
â”œâ”€â”€ therapy_utils.py        # Reusable therapy logic (testable, typed)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example            # Template for environment variables
â”œâ”€â”€ .gitignore              # Git ignore rules (secrets safe)
â”œâ”€â”€ DEPLOYMENT.md           # Deployment guide
â”œâ”€â”€ Readme.md               # Project overview + features
â”‚
â”œâ”€â”€ therapist_fusion_lite.py # Voice-only (no TensorFlow needed)
â”œâ”€â”€ therapist_core.py       # Legacy voice-only core
â”œâ”€â”€ therapist_fusion.py     # Full vision+voice (requires GPU)
â”œâ”€â”€ test_vision.py          # Camera emotion test
â””â”€â”€ check_models.py         # API model probe
```

---

## ğŸ¯ Key Features

### 1. **Solution-Focused Therapy**
- Validates emotions
- Offers specific coping strategies
- Keeps responses under 3 sentences
- Uses CBT techniques

### 2. **Multi-Channel Intelligence**
- Emotion trajectory tracking
- Contradiction detection ("You say fine, but you sound sad")
- Playbook selection based on emotion + intent
- Adaptive response pacing

### 3. **Safety Protocol**
- Real-time self-harm keyword detection
- Crisis response triggers
- Immediate escalation guidance
- Logged for audit trail

### 4. **Session Intelligence**
- Tracks emotion over time
- Records all conversation turns
- Generates end-of-session summary
- Optional session persistence

### 5. **Production Hardening**
- Structured logging (file + console)
- Graceful error handling
- Signal handlers for clean shutdown
- No secrets in logs (API keys masked)
- Type hints on all functions

---

## âš™ï¸ Configuration (`.env`)

| Variable | Default | Purpose |
|----------|---------|---------|
| `GEMINI_API_KEY` | (none) | **REQUIRED** - Your Gemini API key |
| `APP_ENV` | development | Set to "production" for deployment |
| `DEBUG_MODE` | False | Enable debug logging |
| `LOG_LEVEL` | INFO | DEBUG, INFO, WARNING, ERROR |
| `MICROPHONE_INDEX` | 0 | Audio input device (0=default) |
| `SPEECH_TIMEOUT` | 5 | Seconds to wait for user speech |
| `USE_VISION` | False | Enable vision (requires TensorFlow) |
| `ENABLE_SAFETY_NET` | True | Enable self-harm detection |
| `LOG_SESSIONS` | False | Save sessions to JSON files |
| `MODEL_NAME` | gemini-2.5-flash | Which Gemini model to use |

---

## ğŸ“Š What Happens in a Session

```
User speaks â†’ Transcribed â†’ Gemini processes with context
                              (emotion history, playbook, pace)
                              â†“
                         AI generates response
                              â†“
                         Spoken back to user
                              â†“
                         Logged to session + log file
                              â†“
                         (On exit) Summary generated
```

---

## ğŸ›¡ï¸ Security & Privacy

âœ… **Production hardening:**
- API keys loaded from environment (never hardcoded)
- `.env` in `.gitignore` (never committed)
- API keys redacted from logs
- Session files optional + controlled
- No telemetry or external tracking

---

## ğŸ§ª Testing

### Test mode (verbose logging):
```bash
$env:APP_ENV="development"; $env:DEBUG_MODE="true"; python main.py
```

### Check configuration:
```bash
python -c "from config import Config; Config.validate(); print(Config.get_masked_config())"
```

### Verify dependencies:
```bash
pip install -r requirements.txt --check
```

---

## ğŸ“ˆ Production Deployment

### Docker (Optional)
```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["python", "main.py"]
```

### Environment Variables
Set these in your deployment platform:
```
GEMINI_API_KEY=your_key
APP_ENV=production
DEBUG_MODE=false
LOG_LEVEL=INFO
```

### Monitoring
- Check `feelio.log` for all activity
- Set up log aggregation (ELK, Datadog, etc.)
- Alert on "ERROR" or "âš ï¸" markers

---

## ğŸ¨ Frontend Integration

Use the **Bolt/Lovable prompt** from Readme.md to generate a sophisticated UI that connects to this backend via WebSocket or REST API.

Frontend should:
- Stream user audio to `/api/listen`
- Display Gemini responses in real-time
- Show emotion tag + trajectory sparkline
- Display current playbook
- Handle crisis protocol visually

---

## ğŸ“ API Reference (for frontend integration)

### Core Classes

**FeelioTherapist** (in `main.py`)
```python
therapist = FeelioTherapist(config)
therapist.run()  # Start conversation loop
```

**AudioManager** (in `audio_module.py`)
```python
audio = AudioManager()
text = audio.listen_to_user()           # Returns transcribed text or None
audio.speak_response(text, slow=False)  # Play TTS
```

**SessionLog** (in `therapy_utils.py`)
```python
log = SessionLog()
log.add_turn(user_text, ai_text, emotion)
log.get_emotion_timeline()
log.get_recent_turns()
```

---

## ğŸ› Troubleshooting

| Problem | Solution |
|---------|----------|
| `GEMINI_API_KEY is not set` | Edit `.env`, add your API key |
| Microphone not detected | Try `MICROPHONE_INDEX=1` or `2` in `.env` |
| TensorFlow errors | Use `main.py` (lite mode) - no vision needed |
| Slow response | Check internet; consider increasing `RESPONSE_MAX_LENGTH` |
| Session not saving | Create `session_logs/` folder, set `LOG_SESSIONS=true` |
| Permission denied on log file | Check write permissions in project directory |

---

## ğŸ“š Code Quality

- **Type hints**: All functions have type annotations
- **Docstrings**: Comprehensive docs on every function
- **Error handling**: Try-catch blocks in all critical sections
- **Logging**: Every important action logged
- **Modularity**: Clear separation of concerns

---

## ğŸ¯ Next Steps

1. **Run it**: `python main.py`
2. **Test it**: Say "I'm feeling overwhelmed"
3. **Frontend**: Build UI using Bolt/Lovable prompt
4. **Deploy**: Use DEPLOYMENT.md guide
5. **Monitor**: Watch `feelio.log` for issues

---

## ğŸ“ Support

- All logs go to `feelio.log` (plus console)
- Configuration is in `config.py`
- Therapy logic is in `therapy_utils.py`
- Audio handling is in `audio_module.py`

**Status**: âœ… Production-Ready  
**Last Updated**: 2026-01-18  
**License**: MIT (or your choice)
